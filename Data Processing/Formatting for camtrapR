#################################################
## Prepping Snapshot data for camtrapR package ## 
#################################################

############################
## camera trap data frame ##
############################

# set workspace 
setwd("C:/Users/palme516/Desktop/Grad School/Lions/Databases/CT_Official")
rm(list=ls())
library(reshape); library(lubridate); library(plyr)

# read in camera trap data 
dat <- read.csv("complete_consensus_1.9.csv") #not 'uniqued' data
dat <- dat[dat$Season %in% c("S1", "S2") & dat$SiteID %in% c("B04", "C04", "E11", "G13"),] #for example purposes
dat$DateTime <- as.POSIXct(strptime(dat$DateTime, "%Y-%m-%d %H:%M:%S"), tz="GMT") #set tz just so can use ddply
dat$Date <- as.Date(format(dat$DateTime, "%Y-%m-%d"))

# format new data frame
camtraps_snapshot <- unique(dat[c("SiteID", "LocationX", "LocationY")])
camtraps_snapshot <- unique(camtraps_snapshot)
names(camtraps_snapshot) <- c("Station", "utm_x", "utm_y")
camtraps_snapshot$Setup_date <- NA; camtraps_snapshot$Retrieval_date <- NA

# format search effort 
se <- read.csv("search_effort_1.8.csv") # same as 'siterolleffort' csvs generated by search effort code
se <- se[se$GridCell %in% c("B04", "C04", "E11", "G13"),] # for example purposes 
se$StartDate <- as.POSIXct(strptime(se$StartDate, "%m/%d/%Y"), tz="GMT")
se$StopDate <- as.POSIXct(strptime(se$StopDate, "%m/%d/%Y"), tz="GMT")
se <- se[se$StopDate < max(dat$Date) | se$StopDate == max(dat$Date),] #for example purposes 
sites <- unique(se$GridCell)

# set up for loop
# NOTE: here, I know that there were three camera checks, so there are two periods when the cameras were offline between checks; not sure how to automate adding more "problem" periods so for now do it manually
camtraps_snapshot$Problem1_from <- NA; camtraps_snapshot$Problem1_to <- NA
camtraps_snapshot$Problem2_from <- NA; camtraps_snapshot$Problem2_to <- NA

for(i in 1:length(sites)){
  x <- se[se$GridCell == sites[i],]
  camtraps_snapshot$Setup_date[i] <- as.character(min(x$StartDate))
  camtraps_snapshot$Retrieval_date[i] <- as.character(max(x$StopDate))
  camtraps_snapshot$Problem1_from[i] <- as.character(x$StopDate[1])
  camtraps_snapshot$Problem1_to[i] <- as.character(x$StartDate[2])
  camtraps_snapshot$Problem2_from[i] <- as.character(x$StopDate[2])
  camtraps_snapshot$Problem2_to[i] <- as.character(x$StartDate[3])
}

# could add station covariates here if wanted to
covs <- read.csv("../CTCovariates.csv")
covs <- covs[c("SiteID",  "binHab", "ConfDist", "Land.1k")] #choose whichever covariates interested in
names(covs)[1] <- "Station"
camtraps_snapshot <- merge(camtraps_snapshot, covs, all.x=T)

# write csv
write.csv(camtraps_snapshot, "camtraps_snapshot.csv", row.names=F)


##################
## record table ##
##################

# set workspace 
setwd("C:/Users/palme516/Desktop/Grad School/Lions/Databases/CT_Official")
rm(list=ls())

# read in camera trap data 
dat <- read.csv("complete_consensus_1.9.csv")
dat <- dat[c("DateTime", "SiteID", "Species", "Season")]
dat <- dat[dat$Season %in% c("S1", "S2") & dat$SiteID %in% c("B04", "C04", "E11", "G13"),] #for example purposes

# format columns 
dat$DateTime <- as.POSIXct(strptime(dat$DateTime, "%Y-%m-%d %H:%M:%S"), tz="GMT") #set tz just so can use ddply
dat$Date <- as.Date(format(dat$DateTime, "%Y-%m-%d"))
dat$Time <- substr(dat$DateTime,12,19)
dat$Season <- NULL
names(dat) <- c("DateTimeOriginal", "Station", "Species", "Date", "Time")

# order dat and calculate time difs 
dat <- dat[order(dat$Station, dat$Species, dat$DateTimeOriginal),]
dat$index <- paste(dat$Station, dat$Species)
dat$delta.time.secs <- unlist(tapply(dat$DateTimeOriginal, INDEX = dat$index,
                          FUN = function(x) c(0, `units<-`(diff(x), "secs"))))
dat$delta.time.mins <- unlist(tapply(dat$DateTimeOriginal, INDEX = dat$index,
                          FUN = function(x) c(0, `units<-`(diff(x), "mins"))))
dat$delta.time.hours <- unlist(tapply(dat$DateTimeOriginal, INDEX = dat$index,
                          FUN = function(x) c(0, `units<-`(diff(x), "hours"))))
dat$delta.time.days <- unlist(tapply(dat$DateTimeOriginal, INDEX = dat$index,
                          FUN = function(x) c(0, `units<-`(diff(x), "days"))))

# clean
dat$index <- NULL
dat <- dat[!duplicated(dat),]  #bc not using unique'd data (contains all images from all capture events)

# write csv
write.csv(dat, "recordTable.csv", row.names=F)
